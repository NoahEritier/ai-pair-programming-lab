{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMgECiEdjmkeOZvAu6WWGf7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoahEritier/ai-pair-programming-lab/blob/main/ai_pair_programming_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Laboratorio de Pair Programming con IA\n",
        "**Autor:** Mia | T茅cnico Superior en An谩lisis de Sistemas\n",
        "**Tecnolog铆a:** Python, OpenAI/Gemini, Unittest\n",
        "\n",
        "---\n",
        "## Introducci贸n\n",
        "Este notebook documenta una serie de ejercicios pr谩cticos utilizando Inteligencia Artificial como \"Pair Programmer\". El objetivo es demostrar c贸mo utilizar LLMs para refactorizar c贸digo legado, generar pruebas unitarias y depurar errores l贸gicos."
      ],
      "metadata": {
        "id": "keTyz3OtDw98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "webAg21JD1jl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Refactorizaci贸n de C贸digo Legacy"
      ],
      "metadata": {
        "id": "LhaCj0vuD3a_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este ejercicio, tomamos un script de ventas desordenado y procedimental, y utilizamos IA para modularizarlo, tiparlo y hacerlo mantenible."
      ],
      "metadata": {
        "id": "4C-pPS1dEATL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###--- CDIGO ORIGINAL (LEGACY) ---\n",
        "####Simulaci贸n de c贸digo recibido para mantenimiento"
      ],
      "metadata": {
        "id": "mJeWyzzSi1-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"manzana\", 1.5, 10), (\"pera\", 2.0, 5), (\"uva\", 3.5, 2)]\n",
        "t = 0\n",
        "for i in data:\n",
        "    if i[2] > 0:\n",
        "        print(\"vendiendo \" + i[0])\n",
        "        t += i[1] * i[2]\n",
        "    else:\n",
        "        print(\"no hay \" + i[0])\n",
        "print(\"total: \" + str(t))"
      ],
      "metadata": {
        "id": "hck1vAx_jgEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####PAIR PROGRAMMING\n"
      ],
      "metadata": {
        "id": "bBSsQuW7jtcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.api_core import client_options as client_options_lib\n",
        "from google.colab import userdata\n",
        "\n",
        "MY_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "genai.configure(\n",
        "    api_key=MY_API_KEY,\n",
        "    transport=\"rest\",\n",
        "    client_options=client_options_lib.ClientOptions(\n",
        "        api_endpoint=os.getenv(\"GOOGLE_API_BASE\"),\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "qiG6qypzELAz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [m for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
        "print(models)\n",
        "model_flash = genai.GenerativeModel(model_name='gemini-2.5-flash')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6xgYX6E3HOw6",
        "outputId": "c861b466-4ae4-448d-81dc-a8932241d950"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Model(name='models/gemini-2.5-flash',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 2.5 Flash',\n",
            "      description=('Stable version of Gemini 2.5 Flash, our mid-size multimodal model that '\n",
            "                   'supports up to 1 million tokens, released in June of 2025.'),\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=65536,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-2.5-pro',\n",
            "      base_model_id='',\n",
            "      version='2.5',\n",
            "      display_name='Gemini 2.5 Pro',\n",
            "      description='Stable release (June 17th, 2025) of Gemini 2.5 Pro',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=65536,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-2.0-flash-exp',\n",
            "      base_model_id='',\n",
            "      version='2.0',\n",
            "      display_name='Gemini 2.0 Flash Experimental',\n",
            "      description='Gemini 2.0 Flash Experimental',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40), Model(name='models/gemini-2.0-flash',\n",
            "      base_model_id='',\n",
            "      version='2.0',\n",
            "      display_name='Gemini 2.0 Flash',\n",
            "      description='Gemini 2.0 Flash',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40), Model(name='models/gemini-2.0-flash-001',\n",
            "      base_model_id='',\n",
            "      version='2.0',\n",
            "      display_name='Gemini 2.0 Flash 001',\n",
            "      description=('Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model '\n",
            "                   'for scaling across diverse tasks, released in January of 2025.'),\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40), Model(name='models/gemini-2.0-flash-lite-001',\n",
            "      base_model_id='',\n",
            "      version='2.0',\n",
            "      display_name='Gemini 2.0 Flash-Lite 001',\n",
            "      description='Stable version of Gemini 2.0 Flash-Lite',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40), Model(name='models/gemini-2.0-flash-lite',\n",
            "      base_model_id='',\n",
            "      version='2.0',\n",
            "      display_name='Gemini 2.0 Flash-Lite',\n",
            "      description='Gemini 2.0 Flash-Lite',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40), Model(name='models/gemini-2.0-flash-lite-preview-02-05',\n",
            "      base_model_id='',\n",
            "      version='preview-02-05',\n",
            "      display_name='Gemini 2.0 Flash-Lite Preview 02-05',\n",
            "      description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40), Model(name='models/gemini-2.0-flash-lite-preview',\n",
            "      base_model_id='',\n",
            "      version='preview-02-05',\n",
            "      display_name='Gemini 2.0 Flash-Lite Preview',\n",
            "      description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40), Model(name='models/gemini-exp-1206',\n",
            "      base_model_id='',\n",
            "      version='2.5-exp-03-25',\n",
            "      display_name='Gemini Experimental 1206',\n",
            "      description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=65536,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-2.5-flash-preview-tts',\n",
            "      base_model_id='',\n",
            "      version='gemini-2.5-flash-exp-tts-2025-05-19',\n",
            "      display_name='Gemini 2.5 Flash Preview TTS',\n",
            "      description='Gemini 2.5 Flash Preview TTS',\n",
            "      input_token_limit=8192,\n",
            "      output_token_limit=16384,\n",
            "      supported_generation_methods=['countTokens', 'generateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-2.5-pro-preview-tts',\n",
            "      base_model_id='',\n",
            "      version='gemini-2.5-pro-preview-tts-2025-05-19',\n",
            "      display_name='Gemini 2.5 Pro Preview TTS',\n",
            "      description='Gemini 2.5 Pro Preview TTS',\n",
            "      input_token_limit=8192,\n",
            "      output_token_limit=16384,\n",
            "      supported_generation_methods=['countTokens', 'generateContent', 'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemma-3-1b-it',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemma 3 1B',\n",
            "      description='',\n",
            "      input_token_limit=32768,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=None,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemma-3-4b-it',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemma 3 4B',\n",
            "      description='',\n",
            "      input_token_limit=32768,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=None,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemma-3-12b-it',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemma 3 12B',\n",
            "      description='',\n",
            "      input_token_limit=32768,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=None,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemma-3-27b-it',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemma 3 27B',\n",
            "      description='',\n",
            "      input_token_limit=131072,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=None,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemma-3n-e4b-it',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemma 3n E4B',\n",
            "      description='',\n",
            "      input_token_limit=8192,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=None,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemma-3n-e2b-it',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemma 3n E2B',\n",
            "      description='',\n",
            "      input_token_limit=8192,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=None,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-flash-latest',\n",
            "      base_model_id='',\n",
            "      version='Gemini Flash Latest',\n",
            "      display_name='Gemini Flash Latest',\n",
            "      description='Latest release of Gemini Flash',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=65536,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-flash-lite-latest',\n",
            "      base_model_id='',\n",
            "      version='Gemini Flash-Lite Latest',\n",
            "      display_name='Gemini Flash-Lite Latest',\n",
            "      description='Latest release of Gemini Flash-Lite',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=65536,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-pro-latest',\n",
            "      base_model_id='',\n",
            "      version='Gemini Pro Latest',\n",
            "      display_name='Gemini Pro Latest',\n",
            "      description='Latest release of Gemini Pro',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=65536,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-2.5-flash-lite',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 2.5 Flash-Lite',\n",
            "      description='Stable version of Gemini 2.5 Flash-Lite, released in July of 2025',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=65536,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-2.5-flash-image-preview',\n",
            "      base_model_id='',\n",
            "      version='2.0',\n",
            "      display_name='Nano Banana',\n",
            "      description='Gemini 2.5 Flash Preview Image',\n",
            "      input_token_limit=32768,\n",
            "      output_token_limit=32768,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=1.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-2.5-flash-image',\n",
            "      base_model_id='',\n",
            "      version='2.0',\n",
            "      display_name='Nano Banana',\n",
            "      description='Gemini 2.5 Flash Preview Image',\n",
            "      input_token_limit=32768,\n",
            "      output_token_limit=32768,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=1.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-2.5-flash-preview-09-2025',\n",
            "      base_model_id='',\n",
            "      version='Gemini 2.5 Flash Preview 09-2025',\n",
            "      display_name='Gemini 2.5 Flash Preview Sep 2025',\n",
            "      description='Gemini 2.5 Flash Preview Sep 2025',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=65536,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-2.5-flash-lite-preview-09-2025',\n",
            "      base_model_id='',\n",
            "      version='2.5-preview-09-25',\n",
            "      display_name='Gemini 2.5 Flash-Lite Preview Sep 2025',\n",
            "      description='Preview release (Septempber 25th, 2025) of Gemini 2.5 Flash-Lite',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=65536,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-3-pro-preview',\n",
            "      base_model_id='',\n",
            "      version='3-pro-preview-11-2025',\n",
            "      display_name='Gemini 3 Pro Preview',\n",
            "      description='Gemini 3 Pro Preview',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=65536,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-3-flash-preview',\n",
            "      base_model_id='',\n",
            "      version='3-flash-preview-12-2025',\n",
            "      display_name='Gemini 3 Flash Preview',\n",
            "      description='Gemini 3 Flash Preview',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=65536,\n",
            "      supported_generation_methods=['generateContent',\n",
            "                                    'countTokens',\n",
            "                                    'createCachedContent',\n",
            "                                    'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-3-pro-image-preview',\n",
            "      base_model_id='',\n",
            "      version='3.0',\n",
            "      display_name='Nano Banana Pro',\n",
            "      description='Gemini 3 Pro Image Preview',\n",
            "      input_token_limit=131072,\n",
            "      output_token_limit=32768,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=1.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/nano-banana-pro-preview',\n",
            "      base_model_id='',\n",
            "      version='3.0',\n",
            "      display_name='Nano Banana Pro',\n",
            "      description='Gemini 3 Pro Image Preview',\n",
            "      input_token_limit=131072,\n",
            "      output_token_limit=32768,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'batchGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=1.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-robotics-er-1.5-preview',\n",
            "      base_model_id='',\n",
            "      version='1.5-preview',\n",
            "      display_name='Gemini Robotics-ER 1.5 Preview',\n",
            "      description='Gemini Robotics-ER 1.5 Preview',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=65536,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/gemini-2.5-computer-use-preview-10-2025',\n",
            "      base_model_id='',\n",
            "      version='Gemini 2.5 Computer Use Preview 10-2025',\n",
            "      display_name='Gemini 2.5 Computer Use Preview 10-2025',\n",
            "      description='Gemini 2.5 Computer Use Preview 10-2025',\n",
            "      input_token_limit=131072,\n",
            "      output_token_limit=65536,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64), Model(name='models/deep-research-pro-preview-12-2025',\n",
            "      base_model_id='',\n",
            "      version='deepthink-exp-05-20',\n",
            "      display_name='Deep Research Pro Preview (Dec-12-2025)',\n",
            "      description='Preview release (December 12th, 2025) of Deep Research Pro',\n",
            "      input_token_limit=131072,\n",
            "      output_token_limit=65536,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(prompt,\n",
        "                  model=model_flash,\n",
        "                  temperature=0.0):\n",
        "    return model_flash.generate_content(prompt,\n",
        "                                  generation_config={'temperature':temperature})"
      ],
      "metadata": {
        "id": "2IIgDklEH96Y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "I don't think this code is the best way to do it in Python, can you help me?\n",
        "\n",
        "{question}\n",
        "\n",
        "Please modularize the functions, add Type Hinting and make the code maintainable. Explain each step.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "j4CoiwubIGnu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = data = [(\"manzana\", 1.5, 10), (\"pera\", 2.0, 5), (\"uva\", 3.5, 2)]\n",
        "t = 0\n",
        "for i in data:\n",
        "    if i[2] > 0:\n",
        "        print(\"vendiendo \" + i[0])\n",
        "        t += i[1] * i[2]\n",
        "    else:\n",
        "        print(\"no hay \" + i[0])\n",
        "print(\"total: \" + str(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahqbVkPBIdNy",
        "outputId": "91675726-9c9f-4ae5-b4da-832ccb7f273a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vendiendo manzana\n",
            "vendiendo pera\n",
            "vendiendo uva\n",
            "total: 32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = generate_text(\n",
        "    prompt = prompt_template.format(question=question)\n",
        ")\n",
        "print(completion.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YotXsyrGIYjk",
        "outputId": "795ee27c-4907-4897-c3b2-c15ff56b1b19"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You're absolutely right! Using raw tuples like `('manzana', 1.5, 10)` is a common starting point, but it quickly becomes hard to read, maintain, and prone to errors as your codebase grows. You have to remember that `item[0]` is the name, `item[1]` is the price, and `item[2]` is the quantity. This is often called \"magic numbers\" or \"magic indices.\"\n",
            "\n",
            "Let's refactor this into a more Pythonic, modular, and maintainable solution using `dataclasses` for structured data, clear functions, and type hinting.\n",
            "\n",
            "---\n",
            "\n",
            "### The Problem with the Original Approach (Implicit)\n",
            "\n",
            "Your current data structure: `[('manzana', 1.5, 10), ('pera', 2.0, 5), ('uva', 3.5, 2)]`\n",
            "\n",
            "1.  **Lack of Readability:** What do `1.5` and `10` represent without context? You have to infer their meaning.\n",
            "2.  **Error Prone:** It's easy to mix up indices. If you accidentally write `item[2]` when you meant `item[1]`, Python won't complain until runtime, and the error might be subtle.\n",
            "3.  **Hard to Extend:** If you want to add a new field (e.g., `category`, `product_id`), you have to remember its new index everywhere.\n",
            "4.  **Not Self-Documenting:** The structure itself doesn't tell you anything about the data it holds.\n",
            "\n",
            "---\n",
            "\n",
            "### The Improved Pythonic Approach\n",
            "\n",
            "We'll use the following:\n",
            "\n",
            "1.  **`dataclasses`**: A powerful way to create classes that are primarily used to store data. They provide automatic `__init__`, `__repr__`, `__eq__`, etc., making them perfect for this scenario.\n",
            "2.  **Type Hinting**: Explicitly declare the expected types for function arguments, return values, and class attributes. This improves readability, helps with static analysis (linters, IDEs), and makes the code more robust.\n",
            "3.  **Modular Functions**: Break down operations into small, focused functions, each responsible for a single task.\n",
            "4.  **Clear Variable Names**: Use descriptive names for variables and functions.\n",
            "\n",
            "---\n",
            "\n",
            "### Step-by-Step Explanation and Code\n",
            "\n",
            "Let's break down the process:\n",
            "\n",
            "#### Step 1: Define a Data Structure using `dataclasses`\n",
            "\n",
            "Instead of tuples, we'll create a `Product` class using `dataclasses`. This makes our data self-documenting and provides named attributes.\n",
            "\n",
            "```python\n",
            "from dataclasses import dataclass\n",
            "from typing import List, Tuple, Optional\n",
            "\n",
            "# 1. Define a Data Structure using dataclasses\n",
            "#    - @dataclass decorator automatically generates methods like __init__, __repr__, __eq__.\n",
            "#    - Type hints (name: str, price: float, quantity: int) clearly define the expected data types\n",
            "#      for each attribute, improving readability and enabling static analysis.\n",
            "#    - We add a 'total_value' property for convenience, which calculates the value of a single product.\n",
            "@dataclass\n",
            "class Product:\n",
            "    \"\"\"\n",
            "    Represents a single product with its name, price, and quantity.\n",
            "    \"\"\"\n",
            "    name: str\n",
            "    price: float\n",
            "    quantity: int\n",
            "\n",
            "    @property\n",
            "    def total_value(self) -> float:\n",
            "        \"\"\"\n",
            "        Calculates the total value of this product (price * quantity).\n",
            "        \"\"\"\n",
            "        return self.price * self.quantity\n",
            "\n",
            "# Example of how a Product object looks:\n",
            "# product = Product(name=\"manzana\", price=1.5, quantity=10)\n",
            "# print(product)          # Output: Product(name='manzana', price=1.5, quantity=10)\n",
            "# print(product.name)     # Output: manzana\n",
            "# print(product.total_value) # Output: 15.0\n",
            "```\n",
            "\n",
            "#### Step 2: Function to Convert Raw Data to `Product` Objects\n",
            "\n",
            "We need a function to transform your initial list of tuples into a list of `Product` objects. This is a common \"data ingestion\" step.\n",
            "\n",
            "```python\n",
            "# 2. Function to Convert Raw Data to Product Objects\n",
            "#    - This function takes the original list of tuples and converts each tuple\n",
            "#      into a more structured and readable Product object.\n",
            "#    - Type hints:\n",
            "#      - raw_data: List[Tuple[str, float, int]] indicates it expects a list\n",
            "#        where each element is a tuple containing a string, a float, and an integer.\n",
            "#      - -> List[Product] indicates it returns a list of Product objects.\n",
            "def convert_raw_data_to_products(raw_data: List[Tuple[str, float, int]]) -> List[Product]:\n",
            "    \"\"\"\n",
            "    Converts a list of raw product tuples into a list of Product objects.\n",
            "\n",
            "    Args:\n",
            "        raw_data: A list of tuples, where each tuple is (name: str, price: float, quantity: int).\n",
            "\n",
            "    Returns:\n",
            "        A list of Product objects.\n",
            "    \"\"\"\n",
            "    products: List[Product] = []\n",
            "    for item in raw_data:\n",
            "        # Unpacking the tuple directly makes the assignment clear\n",
            "        name, price, quantity = item\n",
            "        products.append(Product(name=name, price=price, quantity=quantity))\n",
            "    return products\n",
            "\n",
            "# Example usage:\n",
            "# raw_inventory = [('manzana', 1.5, 10), ('pera', 2.0, 5), ('uva', 3.5, 2)]\n",
            "# inventory = convert_raw_data_to_products(raw_inventory)\n",
            "# print(inventory)\n",
            "# Output: [Product(name='manzana', price=1.5, quantity=10), ...]\n",
            "```\n",
            "\n",
            "#### Step 3: Function to Display Products\n",
            "\n",
            "A dedicated function to print the product information in a user-friendly format.\n",
            "\n",
            "```python\n",
            "# 3. Function to Display Products\n",
            "#    - This function takes a list of Product objects and prints their details.\n",
            "#    - Type hints:\n",
            "#      - products: List[Product] expects a list of Product objects.\n",
            "#      - -> None indicates the function does not return any value (it performs an action).\n",
            "def display_products(products: List[Product]) -> None:\n",
            "    \"\"\"\n",
            "    Prints the details of each product in a formatted way.\n",
            "\n",
            "    Args:\n",
            "        products: A list of Product objects to display.\n",
            "    \"\"\"\n",
            "    if not products:\n",
            "        print(\"No products to display.\")\n",
            "        return\n",
            "\n",
            "    print(\"\\n--- Current Inventory ---\")\n",
            "    for product in products:\n",
            "        print(f\"  - {product.name.capitalize()}: \"\n",
            "              f\"Price=${product.price:.2f}, \"\n",
            "              f\"Quantity={product.quantity}, \"\n",
            "              f\"Total Value=${product.total_value:.2f}\")\n",
            "    print(\"-------------------------\\n\")\n",
            "\n",
            "# Example usage:\n",
            "# display_products(inventory)\n",
            "```\n",
            "\n",
            "#### Step 4: Function to Calculate Total Inventory Value\n",
            "\n",
            "This function aggregates the `total_value` of all products in the inventory.\n",
            "\n",
            "```python\n",
            "# 4. Function to Calculate Total Inventory Value\n",
            "#    - This function iterates through the list of products and sums their individual total values.\n",
            "#    - Type hints:\n",
            "#      - products: List[Product] expects a list of Product objects.\n",
            "#      - -> float indicates it returns a floating-point number (the total value).\n",
            "def calculate_total_inventory_value(products: List[Product]) -> float:\n",
            "    \"\"\"\n",
            "    Calculates the total monetary value of all products in the inventory.\n",
            "\n",
            "    Args:\n",
            "        products: A list of Product objects.\n",
            "\n",
            "    Returns:\n",
            "        The total value of the inventory as a float.\n",
            "    \"\"\"\n",
            "    return sum(product.total_value for product in products)\n",
            "\n",
            "# Example usage:\n",
            "# total_value = calculate_total_inventory_value(inventory)\n",
            "# print(f\"Total inventory value: ${total_value:.2f}\")\n",
            "```\n",
            "\n",
            "#### Step 5: Function to Find Low Stock Products\n",
            "\n",
            "A function to filter products based on a quantity threshold.\n",
            "\n",
            "```python\n",
            "# 5. Function to Find Low Stock Products\n",
            "#    - This function filters the product list to find items with quantity below a given threshold.\n",
            "#    - Type hints:\n",
            "#      - products: List[Product] expects a list of Product objects.\n",
            "#      - threshold: int expects an integer for the low stock limit.\n",
            "#      - -> List[Product] indicates it returns a new list of Product objects (those in low stock).\n",
            "def get_low_stock_products(products: List[Product], threshold: int) -> List[Product]:\n",
            "    \"\"\"\n",
            "    Identifies products with quantity below a specified threshold.\n",
            "\n",
            "    Args:\n",
            "        products: A list of Product objects.\n",
            "        threshold: The quantity level considered as low stock.\n",
            "\n",
            "    Returns:\n",
            "        A list of Product objects that are in low stock.\n",
            "    \"\"\"\n",
            "    return [product for product in products if product.quantity < threshold]\n",
            "\n",
            "# Example usage:\n",
            "# low_stock = get_low_stock_products(inventory, 5)\n",
            "# print(\"Low stock products:\")\n",
            "# display_products(low_stock)\n",
            "```\n",
            "\n",
            "#### Step 6: Function to Update Product Quantity (Example of Modification)\n",
            "\n",
            "This demonstrates how to modify an existing product's quantity. Note that `dataclasses` are mutable by default, which is fine for this use case. If you needed immutable products, you'd use `frozen=True` in the decorator and return a *new* `Product` object on modification.\n",
            "\n",
            "```python\n",
            "# 6. Function to Update Product Quantity\n",
            "#    - This function searches for a product by name and updates its quantity.\n",
            "#    - Type hints:\n",
            "#      - products: List[Product] expects a list of Product objects (which might be modified).\n",
            "#      - product_name: str expects the name of the product to update.\n",
            "#      - new_quantity: int expects the new quantity value.\n",
            "#      - -> bool indicates it returns True if the update was successful, False otherwise.\n",
            "def update_product_quantity(products: List[Product], product_name: str, new_quantity: int) -> bool:\n",
            "    \"\"\"\n",
            "    Updates the quantity of a specific product in the inventory.\n",
            "\n",
            "    Args:\n",
            "        products: The list of Product objects (will be modified in place).\n",
            "        product_name: The name of the product to update.\n",
            "        new_quantity: The new quantity for the product.\n",
            "\n",
            "    Returns:\n",
            "        True if the product was found and updated, False otherwise.\n",
            "    \"\"\"\n",
            "    for product in products:\n",
            "        if product.name.lower() == product_name.lower():\n",
            "            product.quantity = new_quantity\n",
            "            print(f\"Updated {product.name} quantity to {new_quantity}.\")\n",
            "            return True\n",
            "    print(f\"Product '{product_name}' not found.\")\n",
            "    return False\n",
            "\n",
            "# Example usage:\n",
            "# update_product_quantity(inventory, \"manzana\", 12)\n",
            "# display_products(inventory)\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "### Putting It All Together (Complete Code)\n",
            "\n",
            "```python\n",
            "from dataclasses import dataclass\n",
            "from typing import List, Tuple, Optional\n",
            "\n",
            "# --- Step 1: Define a Data Structure using dataclasses ---\n",
            "@dataclass\n",
            "class Product:\n",
            "    \"\"\"\n",
            "    Represents a single product with its name, price, and quantity.\n",
            "    \"\"\"\n",
            "    name: str\n",
            "    price: float\n",
            "    quantity: int\n",
            "\n",
            "    @property\n",
            "    def total_value(self) -> float:\n",
            "        \"\"\"\n",
            "        Calculates the total value of this product (price * quantity).\n",
            "        \"\"\"\n",
            "        return self.price * self.quantity\n",
            "\n",
            "# --- Step 2: Function to Convert Raw Data to Product Objects ---\n",
            "def convert_raw_data_to_products(raw_data: List[Tuple[str, float, int]]) -> List[Product]:\n",
            "    \"\"\"\n",
            "    Converts a list of raw product tuples into a list of Product objects.\n",
            "\n",
            "    Args:\n",
            "        raw_data: A list of tuples, where each tuple is (name: str, price: float, quantity: int).\n",
            "\n",
            "    Returns:\n",
            "        A list of Product objects.\n",
            "    \"\"\"\n",
            "    products: List[Product] = []\n",
            "    for item in raw_data:\n",
            "        name, price, quantity = item  # Unpacking the tuple directly\n",
            "        products.append(Product(name=name, price=price, quantity=quantity))\n",
            "    return products\n",
            "\n",
            "# --- Step 3: Function to Display Products ---\n",
            "def display_products(products: List[Product]) -> None:\n",
            "    \"\"\"\n",
            "    Prints the details of each product in a formatted way.\n",
            "\n",
            "    Args:\n",
            "        products: A list of Product objects to display.\n",
            "    \"\"\"\n",
            "    if not products:\n",
            "        print(\"No products to display.\")\n",
            "        return\n",
            "\n",
            "    print(\"\\n--- Current Inventory ---\")\n",
            "    for product in products:\n",
            "        print(f\"  - {product.name.capitalize()}: \"\n",
            "              f\"Price=${product.price:.2f}, \"\n",
            "              f\"Quantity={product.quantity}, \"\n",
            "              f\"Total Value=${product.total_value:.2f}\")\n",
            "    print(\"-------------------------\\n\")\n",
            "\n",
            "# --- Step 4: Function to Calculate Total Inventory Value ---\n",
            "def calculate_total_inventory_value(products: List[Product]) -> float:\n",
            "    \"\"\"\n",
            "    Calculates the total monetary value of all products in the inventory.\n",
            "\n",
            "    Args:\n",
            "        products: A list of Product objects.\n",
            "\n",
            "    Returns:\n",
            "        The total value of the inventory as a float.\n",
            "    \"\"\"\n",
            "    return sum(product.total_value for product in products)\n",
            "\n",
            "# --- Step 5: Function to Find Low Stock Products ---\n",
            "def get_low_stock_products(products: List[Product], threshold: int) -> List[Product]:\n",
            "    \"\"\"\n",
            "    Identifies products with quantity below a specified threshold.\n",
            "\n",
            "    Args:\n",
            "        products: A list of Product objects.\n",
            "        threshold: The quantity level considered as low stock.\n",
            "\n",
            "    Returns:\n",
            "        A list of Product objects that are in low stock.\n",
            "    \"\"\"\n",
            "    return [product for product in products if product.quantity < threshold]\n",
            "\n",
            "# --- Step 6: Function to Update Product Quantity ---\n",
            "def update_product_quantity(products: List[Product], product_name: str, new_quantity: int) -> bool:\n",
            "    \"\"\"\n",
            "    Updates the quantity of a specific product in the inventory.\n",
            "\n",
            "    Args:\n",
            "        products: The list of Product objects (will be modified in place).\n",
            "        product_name: The name of the product to update.\n",
            "        new_quantity: The new quantity for the product.\n",
            "\n",
            "    Returns:\n",
            "        True if the product was found and updated, False otherwise.\n",
            "    \"\"\"\n",
            "    for product in products:\n",
            "        if product.name.lower() == product_name.lower():\n",
            "            product.quantity = new_quantity\n",
            "            print(f\"Updated {product.name} quantity to {new_quantity}.\")\n",
            "            return True\n",
            "    print(f\"Product '{product_name}' not found.\")\n",
            "    return False\n",
            "\n",
            "# --- Main execution block to demonstrate the functions ---\n",
            "if __name__ == \"__main__\":\n",
            "    # Your initial raw data\n",
            "    raw_inventory_data: List[Tuple[str, float, int]] = [\n",
            "        ('manzana', 1.5, 10),\n",
            "        ('pera', 2.0, 5),\n",
            "        ('uva', 3.5, 2),\n",
            "        ('naranja', 1.0, 15),\n",
            "        ('platano', 0.75, 3)\n",
            "    ]\n",
            "\n",
            "    print(\"--- Initializing Inventory ---\")\n",
            "    # Convert raw data into a list of Product objects\n",
            "    inventory: List[Product] = convert_raw_data_to_products(raw_inventory_data)\n",
            "    display_products(inventory)\n",
            "\n",
            "    # Calculate and display total inventory value\n",
            "    total_value: float = calculate_total_inventory_value(inventory)\n",
            "    print(f\"Total inventory value: ${total_value:.2f}\\n\")\n",
            "\n",
            "    # Find and display low stock products\n",
            "    low_stock_threshold: int = 5\n",
            "    low_stock_products: List[Product] = get_low_stock_products(inventory, low_stock_threshold)\n",
            "    print(f\"--- Products with quantity below {low_stock_threshold} ---\")\n",
            "    display_products(low_stock_products)\n",
            "\n",
            "    # Demonstrate updating a product's quantity\n",
            "    print(\"--- Updating Product Quantity ---\")\n",
            "    update_product_quantity(inventory, \"manzana\", 12)\n",
            "    update_product_quantity(inventory, \"platano\", 10)\n",
            "    update_product_quantity(inventory, \"kiwi\", 5) # Product not found example\n",
            "    display_products(inventory) # Show updated inventory\n",
            "\n",
            "    # Recalculate total value after updates\n",
            "    total_value_after_update: float = calculate_total_inventory_value(inventory)\n",
            "    print(f\"Total inventory value after updates: ${total_value_after_update:.2f}\\n\")\n",
            "\n",
            "    # Show low stock again after updates\n",
            "    low_stock_products_after_update: List[Product] = get_low_stock_products(inventory, low_stock_threshold)\n",
            "    print(f\"--- Low stock products after updates (below {low_stock_threshold}) ---\")\n",
            "    display_products(low_stock_products_after_update)\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "### Benefits of this Approach:\n",
            "\n",
            "1.  **Readability and Clarity:**\n",
            "    *   `Product(name='manzana', price=1.5, quantity=10)` is much clearer than `('manzana', 1.5, 10)`.\n",
            "    *   You access attributes by name (`product.name`, `product.price`) instead of error-prone indices (`item[0]`, `item[1]`).\n",
            "    *   The `total_value` property encapsulates a common calculation directly within the `Product` class, making it easy to reuse.\n",
            "\n",
            "2.  **Maintainability:**\n",
            "    *   **Modular Functions:** Each function has a single, clear responsibility. This makes the code easier to understand, test, and debug.\n",
            "    *   **Type Hinting:**\n",
            "        *   Acts as documentation, making it clear what types of data functions expect and return.\n",
            "        *   Helps IDEs (like VS Code, PyCharm) provide better autocompletion and catch type-related errors *before* you run the code.\n",
            "        *   Makes refactoring safer, as changes in data types are immediately visible.\n",
            "    *   **Centralized Data Definition:** If you need to add a new field (e.g., `category`, `product_id`), you only need to modify the `Product` dataclass, and the rest of your code that uses named attributes will adapt naturally.\n",
            "    *   **Testability:** Smaller, focused functions are easier to write unit tests for.\n",
            "\n",
            "3.  **Robustness:**\n",
            "    *   Reduced risk of \"magic index\" errors.\n",
            "    *   Type hints help prevent passing incorrect data types to functions.\n",
            "\n",
            "This refactored code is a significant improvement in terms of Pythonic practices, readability, and long-term maintainability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Generaci贸n de Pruebas Unitarias (Unit Testing)\n",
        "Utilizamos la IA para analizar la l贸gica de negocio y generar casos de prueba autom谩ticos, asegurando la cobertura de casos borde (edge cases)."
      ],
      "metadata": {
        "id": "TAhEKNdJj3dy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###--- CDIGO ORIGINAL ---\n",
        "####Simulaci贸n de c贸digo recibido para testing"
      ],
      "metadata": {
        "id": "Wa7r3mF7kJqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci贸n a probar\n",
        "def verificar_acceso(edad, tiene_suscripcion):\n",
        "    if edad < 18:\n",
        "        return False\n",
        "    if tiene_suscripcion:\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "WAptILT0kDsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###PAIR PROGRAMMING"
      ],
      "metadata": {
        "id": "ZUJx0Aw4kerF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.api_core import client_options as client_options_lib\n",
        "from google.colab import userdata\n",
        "\n",
        "MY_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "genai.configure(\n",
        "    api_key=MY_API_KEY,\n",
        "    transport=\"rest\",\n",
        "    client_options=client_options_lib.ClientOptions(\n",
        "        api_endpoint=os.getenv(\"GOOGLE_API_BASE\"),\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "fezlJ5lJkj6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [m for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
        "print(models)\n",
        "model_flash = genai.GenerativeModel(model_name='gemini-2.5-flash')"
      ],
      "metadata": {
        "id": "67eReysSkqOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(prompt,\n",
        "                  model=model_flash,\n",
        "                  temperature=0.0):\n",
        "    return model_flash.generate_content(prompt,\n",
        "                                  generation_config={'temperature':temperature})"
      ],
      "metadata": {
        "id": "CvmH-clekttH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "I want to test this code, can you help me?\n",
        "\n",
        "{question}\n",
        "\n",
        "Please generate unit tests for the code.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "sXwopFGmkwzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci贸n a probar\n",
        "question = def verificar_acceso(edad, tiene_suscripcion):\n",
        "    if edad < 18:\n",
        "        return False\n",
        "    if tiene_suscripcion:\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "qGw0npJOkzyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = generate_text(\n",
        "    prompt = prompt_template.format(question=question)\n",
        ")\n",
        "print(completion.text)"
      ],
      "metadata": {
        "id": "hTdbP9JQk4p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MVDR_lsplPBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Debugging y Documentaci贸n\n",
        "An谩lisis de un error l贸gico (ZeroDivisionError) en un algoritmo de promedios. La IA explica el error y genera la soluci贸n documentada."
      ],
      "metadata": {
        "id": "jgTouRIalQox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###--- CDIGO ORIGINAL ---\n",
        "####Simulaci贸n de c贸digo recibido para debuggear"
      ],
      "metadata": {
        "id": "Ob4TJjM6mZFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codigo_con_bug = \"\"\"\n",
        "def calcular_promedio(numeros):\n",
        "    total = 0\n",
        "    for n in numeros:\n",
        "        total += n\n",
        "    promedio = total / len(numeros)\n",
        "    return promedio\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Upx8bQrbmYpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###PAIR PROGRAMMING"
      ],
      "metadata": {
        "id": "fX4FWl6_m5E2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.api_core import client_options as client_options_lib\n",
        "from google.colab import userdata\n",
        "\n",
        "MY_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "genai.configure(\n",
        "    api_key=MY_API_KEY,\n",
        "    transport=\"rest\",\n",
        "    client_options=client_options_lib.ClientOptions(\n",
        "        api_endpoint=os.getenv(\"GOOGLE_API_BASE\"),\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "P9SnpJZDm8cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [m for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
        "print(models)\n",
        "model_flash = genai.GenerativeModel(model_name='gemini-2.5-flash')"
      ],
      "metadata": {
        "id": "W-MfZz6im_Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(prompt,\n",
        "                  model=model_flash,\n",
        "                  temperature=0.0):\n",
        "    return model_flash.generate_content(prompt,\n",
        "                                  generation_config={'temperature':temperature})"
      ],
      "metadata": {
        "id": "J16CU4c8nBvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "I want to find the bug in this code, can you help me?\n",
        "\n",
        "{question}\n",
        "\n",
        "Please debug the code, explain the error and generate the documentation.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tDOQDgosnIAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = def calcular_promedio(numeros):\n",
        "    total = 0\n",
        "    for n in numeros:\n",
        "        total += n\n",
        "    promedio = total / len(numeros)\n",
        "    return promedio"
      ],
      "metadata": {
        "id": "5T0uvygrnRHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = generate_text(\n",
        "    prompt = prompt_template.format(question=question)\n",
        ")\n",
        "print(completion.text)"
      ],
      "metadata": {
        "id": "SXhUrApQnO3e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}